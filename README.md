#선형회귀
들어온 xData와 yData와 가장 근사한 y=ax+b그래프를 만들어서 예측값을 구한다
각 x에 y가 하나씩
#손실함수
손실함수로는 대표적으로 평균 제곱 오차 둘이 있고 평균 제곱 오차는 |y(출력)-t(예측)| 이고
#경사 하강법
2차 함수에서 기울기를 구해 기울기가 가장 작은 값을 구하는 것
#퍼셉트론
다수의 입력값을 받아 하나의 답을 구함
다수의 x에 y하나
https://wikidocs.net/images/page/24958/perceptrin1_final.PNG
#로지스틱 회귀
로지스틱 함수는 s자로 0에서 1 로 점점 증가 한다 따라서 일정 값에 따라 중간값보다 크거나 작게 나눌 수 있다
#sigmoid Funtion
로지스틱 함수에서 더 발전 된 형태로 일정 이상은 1 일정 이하는 0으로 나오게 됨
